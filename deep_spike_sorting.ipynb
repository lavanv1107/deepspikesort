{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Deep Learning Spike Sorting Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to implement a spike sorting project using deep learning techniques. \n",
    "\n",
    "We utilized the following core libraries:\n",
    "- SpikeInterface and PyNWB are used for extracting recording and sorted data present in NWB files\n",
    "- PyTorch is used for building Tensors, data loaders, and neural networks\n",
    "\n",
    "The general overview of this approach is to create a labeled image dataset which will then be used to train a convolutional neural network (CNN) as a spike detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading an NWB file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are readily available ground-truth datasets in NWB files which contain spikes that have been manually curated by experts. We are going to use the `sub-CSHL049_ses-c99d53e6-c317-4c53-99ba-070b26673ac4_behavior+ecephys+image.nwb` file which can be downloaded from the DANDI archive:\n",
    "https://api.dandiarchive.org/api/assets/7e4fa468-349c-44a9-a482-26898682eed1/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import SpikeInterface modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We followed the instructions for using `SpikeInterface` based on this tutorial:\n",
    "https://github.com/SpikeInterface/spiketutorials/tree/master/Official_Tutorial_SI_0.96_Oct22 \n",
    "\n",
    "Install the latest version of `SpikeInterface` from source as recommended in the **\"From source\"** section here: \n",
    "https://spikeinterface.readthedocs.io/en/latest/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.sorters as ss\n",
    "import spikeinterface.postprocessing as spost\n",
    "import spikeinterface.qualitymetrics as sqm\n",
    "import spikeinterface.comparison as sc\n",
    "import spikeinterface.exporters as sexp\n",
    "import spikeinterface.widgets as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading recording and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_folder = Path(\".\")\n",
    "nwb_file_path = \"sub-CSHL049_ses-c99d53e6-c317-4c53-99ba-070b26673ac4_behavior+ecephys+image.nwb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_nwb = se.read_nwb_recording(file_path=nwb_file_path, electrical_series_name='ElectricalSeriesAp')\n",
    "recording_nwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_nwb.annotate(is_filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_ids = recording_nwb.get_channel_ids()\n",
    "print(channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "channel_ids_slice = channel_ids[0:384]\n",
    "print(channel_ids_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_slice = recording_nwb.channel_slice(channel_ids=channel_ids_slice)\n",
    "recording_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorting_nwb = se.read_nwb_sorting(file_path=nwb_file_path, electrical_series_name='ElectricalSeriesAp')\n",
    "sorting_nwb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_f = spre.bandpass_filter(recording_slice, freq_min=300, freq_max=6000)\n",
    "recording_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "recording_cmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = recording_cmr.get_sampling_frequency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_sub = recording_cmr.frame_slice(start_frame=0*fs, end_frame=300*fs)\n",
    "recording_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorting_sub = sorting_nwb.frame_slice(start_frame=0*fs, end_frame=300*fs)\n",
    "sorting_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_ids = recording_sub.get_channel_ids()\n",
    "print(channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_locations = recording_slice.get_channel_locations()\n",
    "print(channel_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_summary = np.hstack((channel_ids.reshape(-1,1), channel_locations))\n",
    "print(channel_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['channel_id', 'channel_loc_x', 'channel_loc_y']\n",
    "\n",
    "channel_summary_table = pd.DataFrame(channel_summary, columns=column_names)\n",
    "display(channel_summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_summary_table['channel_loc_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_probe_map(recording_sub, with_channel_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using an NWB file that contains both the raw recording and spike sorted data, we can extract information of the already sorted spikes.\n",
    "\n",
    "We need these expert-sorted spikes in order to determine the best channels and frames for plotting our images and labelling them as spikes for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are able to retrieve information about these spikes, we need to create a `WaveformExtractor` object which has mechanisms provided by `SpikeInterface` for computing the spike locations as well as plotting them on the probe.\n",
    "\n",
    "A `WaveformExtractor` object requires a paired `Recording` and `Sorting object` which we already have.\n",
    "\n",
    "More information on waveform extractors can be found here:\n",
    "https://spikeinterface.readthedocs.io/en/latest/modules_gallery/core/plot_4_waveform_extractor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveform_folder = 'waveform'\n",
    "\n",
    "job_kwargs = dict(n_jobs=10, chunk_duration=\"1s\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (base_folder / waveform_folder).is_dir():\n",
    "    waveform = si.load_waveforms(base_folder / waveform_folder)\n",
    "else:\n",
    "    waveform = si.extract_waveforms(\n",
    "        recording_sub,\n",
    "        sorting_sub,\n",
    "        waveform_folder,\n",
    "        ms_before=1.5,\n",
    "        ms_after=2.,\n",
    "        max_spikes_per_unit=None,\n",
    "        overwrite=True,\n",
    "        **job_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the frames each spike occurred (since `SpikeInterface` uses frames instead of seconds) by using the `get_all_spike_trains()` function which returns a list containing two arrays including each spike's unit ID and frame.\n",
    "\n",
    "Each individual spike frame is the rounded product of its corresponding spike time and the sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sorting_sub.get_all_spike_trains())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spikes_table_si = pd.DataFrame({'unit_id':sorting_sub.get_all_spike_trains()[0][1], 'spike_frame':sorting_sub.get_all_spike_trains()[0][0]})\n",
    "spikes_table_si['unit_id'] = spikes_table_si['unit_id'].astype(int)\n",
    "\n",
    "display(spikes_table_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(si.get_template_extremum_channel(waveform, outputs=\"index\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new column and map values from the dictionary based on matching keys\n",
    "spikes_table_si['extremum_channel'] = spikes_table_si['unit_id'].map(si.get_template_extremum_channel(waveform, outputs=\"index\"))\n",
    "spikes_table_si['spike_number'] = range(len(spikes_table_si))\n",
    "\n",
    "display(spikes_table_si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(channel_summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spike_frame = 471\n",
    "trace_snippet = recording_sub.get_traces(start_frame=spike_frame-31, end_frame=spike_frame+33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_snippet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_reshaped = np.dstack((\n",
    "    trace_snippet[:, ::2],\n",
    "    trace_snippet[:, 1::2]\n",
    "))\n",
    "\n",
    "trace_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating timeseries image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import os\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries_path = os.path.join(os.getcwd(), \"timeseries\")\n",
    "\n",
    "if not os.path.exists(timeseries_path):\n",
    "    os.mkdir(timeseries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nthreads = psutil.cpu_count(logical=True)\n",
    "ncores = psutil.cpu_count(logical=False)\n",
    "nthreads_per_core = nthreads // ncores\n",
    "nthreads_available = len(os.sched_getaffinity(0))\n",
    "ncores_available = nthreads_available // nthreads_per_core\n",
    "\n",
    "assert nthreads == os.cpu_count()\n",
    "assert nthreads == mp.cpu_count()\n",
    "\n",
    "print(f'{nthreads=}')\n",
    "print(f'{ncores=}')\n",
    "print(f'{nthreads_per_core=}')\n",
    "print(f'{nthreads_available=}')\n",
    "print(f'{ncores_available=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process spike images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Inspect abundant spike units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_spike_units = spikes_table_si['unit_id'].value_counts().head(20)\n",
    "print(top_spike_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_spike_units_table = spikes_table_si[spikes_table_si['unit_id'].isin(top_spike_units.index)]\n",
    "top_spike_units_table = top_spike_units_table.sort_values(by=['unit_id', 'spike_frame'], ascending=True)\n",
    "display(top_spike_units_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_spike_units = top_spike_units_table['unit_id'].unique()\n",
    "print(top_spike_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_channels = []\n",
    "for i in top_spike_units:\n",
    "    top_channels.append(top_spike_units_table[top_spike_units_table['unit_id']==i]['extremum_channel'].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 5, 7, 13, 33, 40, 52, 67, 148, 286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for unit, channel in zip(top_spike_units, top_channels):\n",
    "    print(f'{unit:<10}{channel:<10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_spike_units = [0, 5, 7, 13, 33, 40, 52, 67, 148, 286]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define multiprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_numpy_images(frames_paths):\n",
    "#     for frame, path in frames_paths:\n",
    "#         # Get the trace\n",
    "#         numpy_image = recording_sub.get_traces(start_frame=frame - 31, end_frame=frame + 33)\n",
    "#         numpy_image_reshaped = np.dstack((\n",
    "#             numpy_image[:, ::2],\n",
    "#             numpy_image[:, 1::2]\n",
    "#         ))\n",
    "\n",
    "#         # Save the numpy array to disk\n",
    "#         image_name = f\"frame_{frame}\"\n",
    "#         np.save(os.path.join(path, image_name), numpy_image_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_batch(batch, path):\n",
    "#     batch_frames_paths = [(frame, path) for frame in batch]\n",
    "#     process_numpy_images(batch_frames_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define the number of processes\n",
    "# num_processes = 128\n",
    "\n",
    "# # Define the batch size\n",
    "# batch_size = 100\n",
    "\n",
    "# # Create a multiprocessing pool\n",
    "# pool = mp.Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Iterate over the units\n",
    "# for unit in top_spike_units:\n",
    "#     unit_path = os.path.join(timeseries_path, f\"unit_{unit}\")\n",
    "#     if not os.path.exists(unit_path):\n",
    "#         os.mkdir(unit_path)\n",
    "\n",
    "#     unit_table = top_spike_units_table[top_spike_units_table['unit_id'] == unit]\n",
    "\n",
    "#     # Get the number of frames\n",
    "#     num_frames = 1000\n",
    "\n",
    "#     # Iterate over the frames in batches\n",
    "#     for i in range(0, num_frames, batch_size):\n",
    "#         batch_frames = unit_table['spike_frame'][i:i+batch_size]\n",
    "\n",
    "#         # Apply multiprocessing to process the batch of frames\n",
    "#         pool.apply_async(process_batch, args=(batch_frames, unit_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process noise images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create list of noise frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spike_frames = spikes_table_si['spike_frame'].to_list()\n",
    "# print(spike_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# noise_frames = [noise_frame - 64 for noise_frame in spike_frames]\n",
    "# print(noise_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display multiprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_frame(noise_frame, noise_path):\n",
    "#     # Get the trace\n",
    "#     numpy_image = recording_sub.get_traces(start_frame=noise_frame - 31, end_frame=noise_frame + 33)\n",
    "#     numpy_image_reshaped = np.dstack((\n",
    "#         numpy_image[:, ::2],\n",
    "#         numpy_image[:, 1::2]\n",
    "#     ))\n",
    "\n",
    "#     # Save the numpy array to disk\n",
    "#     image_name = f\"frame_{noise_frame}\"\n",
    "#     np.save(os.path.join(noise_path, image_name), numpy_image_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process numpy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# noise_path = os.path.join(timeseries_path, \"noise\")\n",
    "\n",
    "# if not os.path.exists(noise_path):\n",
    "#     os.mkdir(noise_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set the number of frames\n",
    "# num_frames = 10000\n",
    "\n",
    "# # Iterate over the frames\n",
    "# for i in range(0, num_frames):\n",
    "#     noise_frame = noise_frames[i]\n",
    "    \n",
    "#     # Apply multiprocessing to process the frame\n",
    "#     pool.apply_async(process_frame, args=(noise_frame, noise_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Close the multiprocessing pool\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfolders = ['unit_' + str(unit) for unit in selected_spike_units]\n",
    "subfolders.append(\"noise\")\n",
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subfolders_dict = {name: index for index, name in enumerate(subfolders)}\n",
    "subfolders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, folder_path):\n",
    "        self.folder_path = folder_path\n",
    "        self.file_paths = self.get_file_paths()\n",
    "        self.label_map = subfolders_dict\n",
    "        \n",
    "    def get_file_paths(self):\n",
    "        file_paths = []\n",
    "        # Iterate over the spike and noise folders\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(self.folder_path, subfolder)\n",
    "            # Get all the numpy files in the subfolder\n",
    "            subfolder_files = [file for file in os.listdir(subfolder_path) if file.endswith('.npy')]\n",
    "            # Add the full path of each file to the list\n",
    "            file_paths.extend([os.path.join(subfolder_path, file) for file in subfolder_files])\n",
    "        return file_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the numpy file as a grayscale image tensor\n",
    "        image = torch.from_numpy(np.load(self.file_paths[idx])).unsqueeze(0).float()\n",
    "        # Extract the folder name from the file path\n",
    "        folder_name = os.path.dirname(self.file_paths[idx])\n",
    "        # Extract the label from the folder name\n",
    "        label = folder_name.split(os.sep)[-1]  # Extract the last folder name\n",
    "        # Assign the numerical label based on the label map\n",
    "        label = self.label_map[label]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries_dataset = NumpyDataset(timeseries_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in timeseries_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(timeseries_dataset))\n",
    "test_size = len(timeseries_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(timeseries_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(train_dataset))\n",
    "print(\"Testing size:\",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv3d(1, 32, kernel_size=2) \n",
    "        self.conv_layer_2 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.conv_layer_3 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        self.conv_layer_2_drop = nn.Dropout2d()\n",
    "        self.conv_layer_3_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fully_connected_layer_1 = nn.Linear(20608, 50)\n",
    "        self.fully_connected_layer_2 = nn.Linear(50, 11)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(torch.squeeze(self.conv_layer_1(x), 4), 2))\n",
    "        #Before this step, input is (batch size, 1, 64, 192, 2)\n",
    "        # After this step, output is (batch size, 1, 32, 96)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_2_drop(self.conv_layer_2(x)), 2))\n",
    "        # After this step, output is (batch size, 1, 16, 48)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_3_drop(self.conv_layer_3(x)), 2))\n",
    "        # After this step, output is (batch size, 1, 8, 24)\n",
    "        \n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fully_connected_layer_1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fully_connected_layer_2(x))\n",
    "        return x\n",
    "\n",
    "model = CNNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(64, 1, 64, 192, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SpikeDeeptector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv_layer_1 = nn.Conv3d(1, 32, kernel_size=2) \n",
    "        self.conv_layer_2 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.conv_layer_3 = nn.Conv2d(64, 128, kernel_size=2)\n",
    "        self.conv_layer_4 = nn.Conv2d(128, 256, kernel_size=2)\n",
    "        # Dropout layers\n",
    "        self.conv_layer_2_drop = nn.Dropout2d()\n",
    "        self.conv_layer_3_drop = nn.Dropout2d()\n",
    "        self.conv_layer_4_drop = nn.Dropout2d()\n",
    "        # Reshape\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Fully connected layers\n",
    "        self.fully_connected_layer_1 = nn.Linear(41216, 500)\n",
    "        self.fully_connected_layer_2 = nn.Linear(500, 250)\n",
    "        self.fully_connected_layer_3 = nn.Linear(250, 125)\n",
    "        self.fully_connected_layer_4 = nn.Linear(125, 11)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Before this step, input is (batch size, 1, 64, 192, 2)\n",
    "        x = F.relu(torch.squeeze(self.conv_layer_1(x), 4))\n",
    "        # After this step, output is (batch size, 1, 32, 96)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_2_drop(self.conv_layer_2(x)), 2))\n",
    "        # After this step, output is (batch size, 1, 16, 48)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_3_drop(self.conv_layer_3(x)), 2))\n",
    "        # After this step, output is (batch size, 1, 8, 24)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_4_drop(self.conv_layer_4(x)), 2))\n",
    "        # After this step, output is (batch size, 1, 8, 24)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fully_connected_layer_1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fully_connected_layer_2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fully_connected_layer_3(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        x = F.relu(self.fully_connected_layer_4(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "spike_deeptector = SpikeDeeptector().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(spike_deeptector, input_size=(64, 1, 64, 192, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss_value = loss.item()\n",
    "            current = batch * len(X)\n",
    "            print(f'loss: {loss_value:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "# Create testing/validation function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "            true_labels.extend(Y.tolist())\n",
    "            predicted_labels.extend(pred.argmax(1).tolist())\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100 * correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')\n",
    "\n",
    "    return test_loss, true_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_model(model):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    epochs = 50\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "\n",
    "        # Train the model and get the losses for this epoch\n",
    "        train_losses = train(train_dataloader, model, cost, optimizer)\n",
    "\n",
    "        # Test the model and get the accuracy for this epoch\n",
    "        test_loss, true_labels, predicted_labels = test(test_dataloader, model, cost)\n",
    "        losses.append(test_loss)\n",
    "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "        accuracies.append(accuracy)  # Append the accuracy within the loop\n",
    "\n",
    "        if epoch + 1 == epochs:\n",
    "            # Plot confusion matrix\n",
    "            classes = list(range(0, 11))\n",
    "            cm = confusion_matrix(true_labels, predicted_labels)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('True')\n",
    "            plt.show()\n",
    "            break\n",
    "\n",
    "    # Plotting the training loss and accuracy over time\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label='Training Loss')\n",
    "    plt.plot(accuracies, label='Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Training Loss and Accuracy over Time')\n",
    "    plt.legend\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(spike_deeptector.parameters(), lr=learning_rate)\n",
    "\n",
    "train_test_model(spike_deeptector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = os.path.join(os.getcwd(), \"models\")\n",
    "\n",
    "if not os.path.exists(models_path):\n",
    "    os.mkdir(models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(model, os.path.join(models_path, 'multi_unit_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "torch.save(spike_deeptector, os.path.join(models_path, 'spike_deeptector.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
