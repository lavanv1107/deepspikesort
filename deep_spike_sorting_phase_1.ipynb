{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Phase 1: Proof of Principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goal of this initial trial is to investigate if it would be possible to train a model to learn neuronal spiking activity. A large part of this process is to first unpack and understand the data we are working with in order to process it as inputs. We also implement different neural network architectures to test out their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore the data in an NWB file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are readily available ground-truth datasets in NWB files which contain spikes that have been manually curated by experts. We are going to use the `sub-CSHL049_ses-c99d53e6-c317-4c53-99ba-070b26673ac4_behavior+ecephys+image.nwb` file which can be downloaded from the DANDI archive:\n",
    "https://api.dandiarchive.org/api/assets/7e4fa468-349c-44a9-a482-26898682eed1/download/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import psutil\n",
    "import multiprocessing as mp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We followed the instructions for using `SpikeInterface` based on this tutorial:\n",
    "https://github.com/SpikeInterface/spiketutorials/tree/master/Official_Tutorial_SI_0.96_Oct22 \n",
    "\n",
    "Install the latest version of `SpikeInterface` from source as recommended in the **\"From source\"** section here: \n",
    "https://spikeinterface.readthedocs.io/en/latest/installation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spikeinterface as si\n",
    "import spikeinterface.extractors as se \n",
    "import spikeinterface.preprocessing as spre\n",
    "import spikeinterface.widgets as sw\n",
    "from spikeinterface.sortingcomponents.peak_detection import detect_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"SpikeInterface version: {si.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import deepspikesort as dss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the NWB file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_folder = Path(\".\")\n",
    "nwb_file = \"sub-CSHL049_ses-c99d53e6-c317-4c53-99ba-070b26673ac4_behavior+ecephys+image.nwb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_nwb = se.read_nwb_recording(file_path=nwb_file, electrical_series_name='ElectricalSeriesAp')\n",
    "recording_nwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_nwb.annotate(is_filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorting_nwb = se.read_nwb_sorting(file_path=nwb_file, electrical_series_name='ElectricalSeriesAp')\n",
    "sorting_nwb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_f = spre.bandpass_filter(recording_nwb, freq_min=300, freq_max=6000)\n",
    "recording_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_cmr = spre.common_reference(recording_f, reference='global', operator='median')\n",
    "recording_cmr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect channels on probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_slice = dss.channel_slice_electricalseriesap(recording_cmr)\n",
    "recording_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "channels_table = dss.extract_channels(recording_slice)\n",
    "display(channels_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_table['channel_loc_x'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.plot_probe_map(recording_slice, with_channel_ids=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect spike events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using an NWB file that contains both the raw recording and spike sorted data, we can extract information of the already sorted spikes.\n",
    "\n",
    "We need these expert-sorted spikes in order to determine the best channels and frames for plotting our images and labelling them as spikes for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we are able to retrieve information about these spikes, we need to create a `WaveformExtractor` object which has mechanisms provided by `SpikeInterface` for computing the spike locations as well as plotting them on the probe.\n",
    "\n",
    "A `WaveformExtractor` object requires a paired `Recording` and `Sorting object` which we already have.\n",
    "\n",
    "More information on waveform extractors can be found here:\n",
    "https://spikeinterface.readthedocs.io/en/latest/modules_gallery/core/plot_4_waveform_extractor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveform_folder = 'waveform'\n",
    "\n",
    "job_kwargs = dict(n_jobs=10, chunk_duration=\"1s\", progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (base_folder / waveform_folder).is_dir():\n",
    "    waveform_nwb = si.load_waveforms(base_folder / waveform_folder)\n",
    "else:\n",
    "    waveform_nwb = si.extract_waveforms(\n",
    "        recording_slice,\n",
    "        sorting_nwb,\n",
    "        waveform_folder,\n",
    "        ms_before=1.5,\n",
    "        ms_after=2.,\n",
    "        max_spikes_per_unit=None,\n",
    "        overwrite=True,\n",
    "        **job_kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveform_nwb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can retrieve the frames each spike occurred (since `SpikeInterface` uses frames instead of seconds) by using the `get_all_spike_trains()` function which returns a list containing two arrays including each spike's unit ID and frame.\n",
    "\n",
    "Each individual spike frame is the rounded product of its corresponding spike time and the sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spikes_table = dss.extract_spikes(sorting_nwb, waveform_nwb)\n",
    "display(spikes_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dss.plot_unit_waveform(recording_slice, spikes_table, unit_id=7, num_waveforms=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how the channels on a Neuropixels probe are arranged in a checkerboard pattern, we want to reshape our trace to better emulate that. This would mean separating the channels into two columns resulting in a 3-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dss.plot_trace_image(recording_slice, 1153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a dataset from sorted spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are running this project on NERSC, we are able to utilize multiprocessing as well as batches in order to speed up the process of generating our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nthreads = psutil.cpu_count(logical=True)\n",
    "ncores = psutil.cpu_count(logical=False)\n",
    "nthreads_per_core = nthreads // ncores\n",
    "nthreads_available = len(os.sched_getaffinity(0))\n",
    "ncores_available = nthreads_available // nthreads_per_core\n",
    "\n",
    "assert nthreads == os.cpu_count()\n",
    "assert nthreads == mp.cpu_count()\n",
    "\n",
    "print(f'{nthreads=}')\n",
    "print(f'{ncores=}')\n",
    "print(f'{nthreads_per_core=}')\n",
    "print(f'{nthreads_available=}')\n",
    "print(f'{ncores_available=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "supervised_dataset_folder = os.path.join(os.getcwd(), \"supervised_dataset\")\n",
    "\n",
    "if not os.path.exists(supervised_dataset_folder):\n",
    "    os.mkdir(supervised_dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process traces as numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to obtain a fairly large dataset of spikes for our model, we want to select units which have at least 1000 spikes within them.\n",
    "\n",
    "As for our noise class, we can select frames that exist in gaps between each of our spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_spike_units = spikes_table['unit_id'].value_counts()\n",
    "top_spike_units = top_spike_units[top_spike_units >= 1000]\n",
    "top_spike_units = top_spike_units.index.tolist()\n",
    "top_spike_units.sort()\n",
    "\n",
    "print('Number of units:', len(top_spike_units))\n",
    "print(top_spike_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise_folder = os.path.join(supervised_dataset_folder, \"noise\")\n",
    "\n",
    "if not os.path.exists(noise_folder):\n",
    "    os.mkdir(noise_folder)\n",
    "    \n",
    "    spike_frames = spikes_table['spike_frame'].to_list()\n",
    "    noise_frames = [noise_frame - 64 for noise_frame in spike_frames]\n",
    "    print(noise_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tensor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folders = ['unit_' + str(unit) for unit in top_spike_units[:100]]\n",
    "dataset_folders.append(\"noise\")\n",
    "print(dataset_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_folders_dict = {name: index for index, name in enumerate(dataset_folders)}\n",
    "print(dataset_folders_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spikes_dataset = dss.TensorDataset(supervised_dataset_folder, dataset_folders, dataset_folders_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_path = os.path.join(supervised_dataset_folder, \"train_dataset_v2.pkl\")\n",
    "test_dataset_path = os.path.join(supervised_dataset_folder, \"test_dataset_v2.pkl\")\n",
    "\n",
    "if not (os.path.exists(train_dataset_path) and os.path.exists(test_dataset_path)):\n",
    "    # Get labels for the entire dataset\n",
    "    labels = []\n",
    "    for _, label in tqdm(spikes_dataset, desc=\"Getting Labels\"):\n",
    "        labels.append(label)\n",
    "\n",
    "    # Split the dataset into train and test sets while maintaining class distribution\n",
    "    train_indices, test_indices = train_test_split(\n",
    "        range(len(spikes_dataset)),\n",
    "        test_size=0.3,\n",
    "        stratify=labels\n",
    "    )\n",
    "\n",
    "    # Create train and test datasets using the indices\n",
    "    train_dataset = [(spikes_dataset[i][0], spikes_dataset[i][1]) for i in tqdm(train_indices, desc=\"Creating Train Dataset\")]\n",
    "    test_dataset = [(spikes_dataset[i][0], spikes_dataset[i][1]) for i in tqdm(test_indices, desc=\"Creating Test Dataset\")]\n",
    "    \n",
    "    with open(train_dataset_path, 'wb') as f:\n",
    "        pickle.dump(train_dataset, f)\n",
    "\n",
    "    with open(test_dataset_path, 'wb') as f:\n",
    "        pickle.dump(test_dataset, f)\n",
    "\n",
    "else:\n",
    "    with open(train_dataset_path, 'rb') as f:\n",
    "        train_dataset = pickle.load(f)\n",
    "    \n",
    "    with open(test_dataset_path, 'rb') as f:\n",
    "        test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get classes and number of items in train and test datasets\n",
    "train_classes = [label for _, label in train_dataset]\n",
    "test_classes = [label for _, label in test_dataset]\n",
    "\n",
    "print('Training dataset:\\n', Counter(train_classes), '\\n')\n",
    "print('Testing dataset:\\n', Counter(test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create DataLoader instances for train and test datasets\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2,\n",
    "    shuffle=True  # Shuffle the train dataset during training\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify spikes and noise with a CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Conv3d(1, 32, kernel_size=(9, 3, 2)) \n",
    "        self.conv_layer_2 = nn.Conv2d(32, 64, kernel_size=4) \n",
    "        \n",
    "        self.conv_layer_2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fully_connected_layer_1 = nn.Linear(35328, 500)\n",
    "        self.fully_connected_layer_2 = nn.Linear(500, 316)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(torch.squeeze(self.conv_layer_1(x), 4), 2))\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv_layer_2_drop(self.conv_layer_2(x)), 2))\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fully_connected_layer_1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fully_connected_layer_2(x))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "model = CNNet().to(device)\n",
    "\n",
    "# Choose optimal parameters\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary(model, input_size=(64, 1, 64, 192, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_folder = os.path.join(os.getcwd(), \"models\")\n",
    "\n",
    "if not os.path.exists(models_folder):\n",
    "    os.mkdir(models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dss = importlib.reload(dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model = dss.TrainModel(train_dataloader,\n",
    "                             test_dataloader,\n",
    "                             device,\n",
    "                             loss_fn,\n",
    "                             optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"sup_1\"\n",
    "\n",
    "train_model.train_test_model(model, model_name, models_folder, epochs=7, classes=top_spike_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize convolutional layer filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vis_model = dss.VisualizeModel(model)\n",
    "vis_model.display_layers_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize filters for first layer\n",
    "vis_model.visualize_layer_filters(0, '3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize filters for second layer\n",
    "vis_model.visualize_layer_filters(1, '2D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model's confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model = dss.TestModel(test_dataset, device, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model.get_confidence_and_probabilities(dataset_folders, 7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpikeSortv2",
   "language": "python",
   "name": "spike_sort_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
